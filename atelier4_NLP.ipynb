{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AbdNasir24/Atelier-2-NLP/blob/main/atelier4_NLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "slideshow": {
          "slide_type": "fragment"
        }
      },
      "source": [
        "1. Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fr1a3Yu2LoI_",
        "outputId": "4c08b970-4d77-4029-f2a6-a0b91bcd813a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.tokenize import word_tokenize\n",
        "import spacy\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error, r2_score, classification_report\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "# Download necessary NLTK data\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "zUVv322iLyaf"
      },
      "outputs": [],
      "source": [
        "# Initialize spaCy lemmatizer and other tools\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "stop_words = set(stopwords.words('english'))\n",
        "stemmer = PorterStemmer()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "tW3gCnU8Lyh3"
      },
      "outputs": [],
      "source": [
        "# Load the dataset\n",
        "df = pd.read_csv('/answers.csv')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "vhEB0KmOLynB"
      },
      "outputs": [],
      "source": [
        "# Initialize spaCy lemmatizer and other tools\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "stop_words = set(stopwords.words('english'))\n",
        "stemmer = PorterStemmer()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "iWwHllObLyqN"
      },
      "outputs": [],
      "source": [
        "# Load the dataset\n",
        "df = pd.read_csv('/answers.csv')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "LyJGBiGAMIwe"
      },
      "outputs": [],
      "source": [
        "# Preprocessing function\n",
        "def preprocess_text(text):\n",
        "    if isinstance(text, float):\n",
        "        return \"\"\n",
        "    # Tokenization\n",
        "    tokens = word_tokenize(text)\n",
        "\n",
        "    # Lowercasing\n",
        "    tokens = [token.lower() for token in tokens]\n",
        "\n",
        "    # Removing stop words\n",
        "    tokens = [token for token in tokens if token not in stop_words]\n",
        "\n",
        "    # Stemming\n",
        "    stemmed_tokens = [stemmer.stem(token) for token in tokens]\n",
        "\n",
        "    # Lemmatization\n",
        "    lemmatized_tokens = [token.lemma_ for token in nlp(\" \".join(stemmed_tokens))]\n",
        "\n",
        "    return \" \".join(lemmatized_tokens)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "QnidWdh-MIt0"
      },
      "outputs": [],
      "source": [
        "# Convert 'correct' column to string type if not already\n",
        "df['answer'] = df['answer'].astype(str)\n",
        "\n",
        "# Remove rows where 'correct' is empty after conversion\n",
        "df = df[df['answer'].str.strip() != \"\"]\n",
        "\n",
        "# Apply preprocessing to the dataset\n",
        "df['processed_text'] = df['answer'].apply(preprocess_text)\n",
        "\n",
        "# Check for empty processed texts and filter them out\n",
        "df = df[df['processed_text'].str.strip() != \"\"]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "N7Z9WgIGMIrD"
      },
      "outputs": [],
      "source": [
        "# Feature extraction\n",
        "vectorizer_tfidf = TfidfVectorizer()\n",
        "X_tfidf = vectorizer_tfidf.fit_transform(df['processed_text'])\n",
        "\n",
        "# Ensure the target variable is numeric\n",
        "df['score'] = pd.to_numeric(df['score'], errors='coerce')\n",
        "\n",
        "# Drop rows with missing target values\n",
        "df = df.dropna(subset=['score'])\n",
        "\n",
        "# Ensure there are no empty rows in X_tfidf\n",
        "non_empty_docs = np.sum(X_tfidf.toarray(), axis=1) > 0\n",
        "X_tfidf = X_tfidf[non_empty_docs]\n",
        "df = df.iloc[non_empty_docs]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gu2hKkx7MIoM",
        "outputId": "1d6fc35d-97fa-423b-d628-656bbe72e1eb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Linear Regression Metrics:\n",
            "Mean Squared Error: 2.5865523262524026\n",
            "Root Mean Squared Error: 1.6082761971292128\n",
            "R2 Score: -1.1193250554250582\n"
          ]
        }
      ],
      "source": [
        "# Regression Example\n",
        "y = df['score']\n",
        "\n",
        "# Split the data\n",
        "X_train_tfidf, X_test_tfidf, y_train, y_test = train_test_split(X_tfidf, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Linear Regression\n",
        "lr_model = LinearRegression()\n",
        "lr_model.fit(X_train_tfidf, y_train)\n",
        "y_pred_lr = lr_model.predict(X_test_tfidf)\n",
        "\n",
        "# Evaluate Linear Regression\n",
        "mse_lr = mean_squared_error(y_test, y_pred_lr)\n",
        "rmse_lr = np.sqrt(mse_lr)\n",
        "r2_lr = r2_score(y_test, y_pred_lr)\n",
        "\n",
        "print(\"Linear Regression Metrics:\")\n",
        "print(\"Mean Squared Error:\", mse_lr)\n",
        "print(\"Root Mean Squared Error:\", rmse_lr)\n",
        "print(\"R2 Score:\", r2_lr)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wM6xSyFCMIlU",
        "outputId": "d89c1911-afb0-467c-f8a9-39782610c6c9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Naive Bayes Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        high       0.85      1.00      0.92       412\n",
            "         low       1.00      0.05      0.09        43\n",
            "      medium       0.00      0.00      0.00        32\n",
            "\n",
            "    accuracy                           0.85       487\n",
            "   macro avg       0.62      0.35      0.34       487\n",
            "weighted avg       0.81      0.85      0.78       487\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "# Classification Example\n",
        "def convert_to_category(score):\n",
        "    if score <= 2:\n",
        "        return 'low'\n",
        "    elif score == 3:\n",
        "        return 'medium'\n",
        "    else:\n",
        "        return 'high'\n",
        "\n",
        "y_categorized = df['score'].apply(convert_to_category)\n",
        "\n",
        "# Split the data\n",
        "X_train_tfidf, X_test_tfidf, y_train, y_test = train_test_split(X_tfidf, y_categorized, test_size=0.2, random_state=42)\n",
        "\n",
        "# Naive Bayes\n",
        "nb_model = MultinomialNB()\n",
        "nb_model.fit(X_train_tfidf, y_train)\n",
        "y_pred_nb = nb_model.predict(X_test_tfidf)\n",
        "\n",
        "# Evaluate Naive Bayes\n",
        "print(\"Naive Bayes Classification Report:\")\n",
        "print(classification_report(y_test, y_pred_nb))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zdUdCbNiNOUS"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xIUyCC0HNORQ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lL9TbspINOOJ"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyNqGp07BNb45R4AdXHIOMr2",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
